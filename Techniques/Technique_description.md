<b>Shadow Ban :</b> https://en.wikipedia.org/wiki/Nudge_theory<br>

Shadow banning is a practice on social media where a user’s content is made invisible or less visible to others without their knowledge. It’s used to curb spam or inappropriate behavior, reducing post reach without deleting the account. Platforms like Twitter, Instagram, or YouTube are said to have used it, though it’s often unofficial and controversial. Users may suspect a shadow ban if they notice a sudden drop in visibility or engagement. The technique raises debates about transparency, censorship, and online free speech.


<b>Nudge :</b> https://en.wikipedia.org/wiki/Character_assassination<br>

Nudge theory involves subtly influencing people’s behavior without restricting choices, often for their benefit. It uses small cues or design changes, like placing healthier food at eye level, to guide decisions. Popularized in behavioral economics, it’s applied in policy and marketing. Critics argue it can feel manipulative if not transparent.


<b>Character Assassination :</b> https://en.wikipedia.org/wiki/Character_assassination

Character assassination is the deliberate spread of false or damaging information to ruin someone’s reputation. It often involves slander, rumors, or exaggerated claims, targeting public figures or rivals. Historically used in politics, it aims to discredit without evidence. The damage can be long-lasting and hard to refute.


<b>Sock Puppet :</b> https://en.wikipedia.org/wiki/Sock_puppet_account<br>

A sock puppet is a fake online identity used to deceive others, often to push agendas or fake support. Common on forums or social media, it amplifies opinions or attacks opponents anonymously. Platforms try to detect them, but they persist. It undermines trust in online discourse.


<b>Bad Jacketing :</b> https://en.wikipedia.org/wiki/Bad-jacketing<br>

Bad jacketing is falsely labeling someone as an informant or traitor within a group to sow distrust. Used by authorities or rivals, it isolates targets and disrupts unity, especially in activist circles. Historically linked to COINTELPRO, it’s a covert betrayal tactic. Suspicion alone can ruin relationships.


<b>Kompromat :</b> https://fr.wikipedia.org/wiki/Kompromat_(renseignement)<br>

Kompromat is compromising material, like scandals or secrets, collected to blackmail or discredit someone. Often used in espionage or politics, it leverages fear of exposure to control targets. Russia’s intelligence is famously associated with it. It’s effective because it exploits personal vulnerabilities.


<b>Cherry Picking :</b> https://fr.wikipedia.org/wiki/Cherry_picking<br>

Cherry picking is selectively presenting data or evidence to support a claim while ignoring contradictions. Common in debates or media, it distorts reality for persuasion. Scientists and propagandists alike use it. It misleads by crafting a one-sided narrative.


<b>Emotional Hijacking :</b> https://www.ei-magazine.com/post/what-is-emotional-hijacking-and-how-can-you-prevent-it<br>

Emotional hijacking triggers an intense emotional response (fear, anger, joy) to bypass rational thinking. Once emotionally charged, a person is more likely to accept a message uncritically. Example: pairing propaganda with shocking imagery.


<b>Ignorant Agent :</b> https://disarmframework.herokuapp.com/technique/7/view<br>

An ignorant agent is someone unknowingly spreading disinformation, manipulated by others. They act sincerely, making their message convincing, often on social media. Part of disinformation campaigns, it exploits trust. Their ignorance shields the true orchestrators.


<b>Clickbait :</b> https://fr.wikipedia.org/wiki/Pi%C3%A8ge_%C3%A0_clics<br>

Clickbait uses sensational or misleading headlines to lure users into clicking content. It prioritizes engagement over substance, common in online media. Titles like “You Won’t Believe This!” drive traffic but often disappoint. It thrives on curiosity and frustration.


<b>Keyword Squatting :</b> https://mediamanipulation.org/definitions/keyword-squatting/<br>

Keyword squatting involves hijacking trending terms to spread unrelated or false content. Used in disinformation, it floods search results or hashtags with noise. Think propaganda piggybacking on breaking news. It confuses and misdirects public attention.


<b>Swarming :</b> https://disarmframework.herokuapp.com/technique/49/view<br>

Swarming is coordinated online attacks by many accounts to overwhelm or harass a target. Often seen in trolling or disinformation, it amplifies impact through sheer volume. Think Twitter pile-ons. It intimidates and drowns out opposition.


<b>Fake Experts :</b> https://disarmframework.herokuapp.com/technique/5/view<br>

Fake experts are unqualified individuals presented as authorities to push a narrative. Common in disinformation, they deceive with credentials or charisma. Think anti-vaccine “doctors.” It exploits trust in expertise to mislead.


<b>Contradictory Injunction :</b> https://fr.wikipedia.org/wiki/Double_contrainte<br>

Contradictory injunction, or double bind, is giving conflicting demands where no response wins. Used in manipulation, it traps victims in confusion or guilt, like “be spontaneous” orders. Psychologically draining, it’s a control tactic.


<b>Doxing :</b> https://fr.wikipedia.org/wiki/Divulgation_de_donn%C3%A9es_personnelles<br>

Doxing is publicly revealing private information, like addresses, to harm or intimidate someone. Often a revenge tactic online, it violates privacy and invites harassment. Think hackers targeting critics. It’s a weapon of exposure.


<b>Cyberbullying :</b> https://disarmframework.herokuapp.com/technique/193/view<br>

Cyberbullying is repeated online harassment to humiliate or distress a target. Using insults, threats, or rumors, it thrives on anonymity. Social media amplifies its reach. It causes real emotional harm.


<b>Seed Distortions :</b> https://disarmframework.herokuapp.com/technique/35/view<br>

Seed distortions plant small lies or half-truths to grow broader misinformation. Subtle and strategic, they spread naturally via shares. Think rumors taking root online. It’s insidious because it feels organic.


<b>Bait Influencer :</b> https://www.rollingstone.com/culture/culture-features/what-is-rage-bait-influencers-making-people-angry-1234976621/<br>

Bait influencers provoke outrage or reactions to boost engagement. They post inflammatory content, like rage-bait, to go viral. Think divisive TikTok rants. It exploits emotions for attention.


<b>Online Polls :</b> https://en.wikipedia.org/wiki/Open-access_poll<br>

Online polls are informal surveys open to manipulation, skewing public perception. Unregulated and unscientific, they’re gamed by bots or brigades. Think Twitter polls swaying opinion. They mimic legitimacy but lack rigor.


<b>Echo Chamber :</b> https://fr.wikipedia.org/wiki/Chambre_d%27%C3%A9cho_(m%C3%A9dias)<br>

An echo chamber is an online space where ideas are reinforced without challenge. Algorithms and groupthink amplify biases, like on partisan forums. It isolates users from dissent. Reality becomes distorted.


<b>Copypasta :</b> https://fr.wikipedia.org/wiki/Copypasta<br>

Copypasta is repetitive, copied text spammed online, often for humor or disruption. Think meme walls flooding comments. It annoys or derails discussions. It’s low-effort noise.


<b>Scarcity Manipulation :</b> https://uxdesign.cc/5-types-of-scarcity-how-to-influence-anyone-using-these-7f309d328dbb<br>

This technique uses the fear of missing out (on time, resources, or opportunities) to prompt quick action without reflection. For example, spreading a rumor that critical information will soon be censored to push people to share it immediately.


<b>Motivate Mediocrity :</b> https://www.tanbou.com/2022/Noam-Chomsky-10-strategies-manipulation.htm<br>

Motivating mediocrity encourages apathy or low standards to keep people docile. Linked to manipulation theories, it praises conformity over ambition. Think “don’t question, just follow.” It stifles progress.


<b>Develop Deep/Cheap Fakes :</b> https://datasociety.net/library/deepfakes-and-cheap-fakes/<br>

Deep and cheap fakes are manipulated media, like AI-altered videos, to deceive. Deep fakes are sophisticated; cheap ones are quick edits. Think fake politician speeches. They erode trust in reality.


<b>Firehose of Falsehood :</b> https://en.wikipedia.org/wiki/Firehose_of_falsehood<br>

Firehose of falsehood is rapid, high-volume lies to overwhelm truth. Used in propaganda, it floods discourse with contradictions. Think Russian disinformation tactics. Volume trumps accuracy.


<b>Dismiss / Distract / Distort / Dismay :</b> https://fromthepenof.com/red-flag-professional-behaviour/discrediting<br>

The 4 Ds discredit foes by dismissing, distracting, distorting, or dismaying. Think smear campaigns dodging facts. It’s a systematic attack on credibility. Opponents are silenced.


<b>Gaslighting :</b> https://en.wikipedia.org/wiki/Gaslighting<br>

Gaslighting manipulates someone into doubting their reality or sanity. Using denial or lies, like “that never happened,” it confuses victims. Think abusive relationships online. It’s psychological sabotage.


<b>Create Inauthentic News Sites :</b> https://disarmframework.herokuapp.com/technique/141/view<br>

Inauthentic news sites mimic legit sources to spread lies. Built for disinformation, they trick readers with fake credibility. Think “breaking news” clones. They pollute trust.


<b>Censorship :</b> https://disarmframework.herokuapp.com/counter/9/view<br>

Censorship suppresses information to control narratives. Governments or platforms block content, like banned posts. Think authoritarian media clamps. It limits free expression.


<b>Illusory Truth Effect :</b> https://en.wikipedia.org/wiki/Illusory_truth_effect<br>

The illusory truth effect makes repeated lies seem true. Familiarity breeds belief, even if false. Think propaganda slogans. It exploits cognitive bias.


<b>Microtarget :</b> https://www.merriam-webster.com/dictionary/microtarget<br>

Microtargeting tailors ads or messages to specific individuals using data. Used in campaigns, it’s precise persuasion. Think Facebook ads hitting voters. It’s powerful but creepy.


<b>Maintaining Guilt and Ignorance :</b> https://www.tanbou.com/2022/Noam-Chomsky-10-strategies-manipulation.htm<br>

Maintaining guilt and ignorance keeps people submissive via shame and confusion. A manipulation tactic, it blames the masses. Think “you’re too dumb to know.” It kills critical thought.


<b>Manipulate Platform Algo :</b> https://github.com/DISARMFoundation/DISARMframeworks/blob/main/generated_pages/techniques/T0121.md

Manipulating platform algorithms games systems to boost content visibility. Using bots or trends, it cheats reach. Think SEO for disinformation. It hijacks attention.

<b>Framing :</b> https://en.wikipedia.org/wiki/Framing_(social_sciences)

Framing manipulates how information is presented to shape its interpretation. For instance, saying "90% success rate" instead of "10% failure rate" alters perception without changing the facts. It’s often used to make a narrative more favorable or alarming.

<b>Bandwagon Effect :</b> https://en.wikipedia.org/wiki/Bandwagon_effect

The bandwagon effect exploits the human tendency to follow the majority. By creating the illusion that an idea or belief is widely accepted ("everyone thinks this"), it pressures individuals to conform without questioning it.
